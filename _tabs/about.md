---
layout: page
icon: fas fa-info-circle
order: 1
---

## About Me

![Profile Picture](/assets/img/avatar.jpg){: width="200" height="200" .rounded-10 }

**Name:** Oluwatunmise Raphael Shuaibu  
**Student ID:** M00960413  
**Programme:** BEng Mechatronics and Robotics Engineering  
**Institution:** Middlesex University London  
**Expected Graduation:** July 2026

### My Background

I'm experienced in robotics systems, computer vision, embedded programming, and industrial automation. I've worked on projects ranging from robotic arm teleoperation with machine learning-based gesture recognition to PLC-based manufacturing systems. My approach is hands-on - I learn by actually doing, spending hours in the lab trying to figure out how things work and communicate with each other.

For a more detailed overview of my work and experience, visit my portfolio site *(coming soon)*.

### Connect With Me

üìß **Email:** Shuaibuoluwatunmise@gmail.com  
üíº **LinkedIn:** [linkedin.com/in/oluwatunmise-shuaibu-881519257](https://linkedin.com/in/oluwatunmise-shuaibu-881519257)  
üíª **GitHub:** [github.com/Shuaibu-oluwatunmise](https://github.com/Shuaibu-oluwatunmise)  
üåê **Portfolio:** *Coming soon*

---

## About This Project

This blog documents my final year project for **BEng Mechatronics and Robotics Engineering** at Middlesex University London.

### Project Overview

**Title:** Perception and SLAM System for Formula Student AI Autonomous Racing

**Duration:** 12 weeks (January - April 2026)

**Objective:** Develop an autonomous perception and simultaneous localization and mapping (SLAM) system for Formula Student AI racing vehicles.

### What I'm Building

The system will:
- Detect racing cones in real-time using computer vision
- Process camera and LiDAR sensor data
- Localize the vehicle position within the environment
- Run in IPG CarMaker simulation environment
- Integrate everything using ROS2 Jazzy

### The Challenge

Formula Student AI is a competitive autonomous racing competition. My perception system must:
- Process sensor data in real-time (<100ms latency)
- Accurately detect and classify colored cones (blue, yellow, orange)
- Handle dynamic racing conditions and varying lighting
- Provide reliable position estimates for path planning

### Technologies & Tools

- **ROS2 Jazzy** - System integration framework
- **Python & C++** - Primary programming languages
- **YOLO** - Cone detection model
- **IPG CarMaker** - Simulation and testing environment
- **OpenCV** - Computer vision processing
- **SLAM Libraries** - SLAM Toolbox, Cartographer, or RTAB-Map (TBD)

### Why I Chose This Project

I've always been drawn to systems that move and make decisions autonomously. This project combines the technical challenge of real-time computer vision with the complexity of building a robot that understands where it is and what's around it. Formula Student AI pushes everything to the limit - you need fast, accurate perception in a high-speed racing environment. It's the kind of problem where you can't cut corners, and I like that. Plus, the idea of working through the full perception pipeline from scratch, rather than just implementing someone else's solution, is exactly the type of hands-on challenge I want to tackle before graduating.

---

## Why This Blog?

I'm documenting my entire development journey - the successes, challenges, bugs, and breakthroughs. This blog serves as:

- **Daily accountability** to stay on track with my 12-week plan
- **Technical documentation** of design decisions and implementation details
- **Learning journal** to reflect on what works and what doesn't
- **Portfolio piece** to showcase my work to future employers and collaborators

Every post captures real progress, real problems, and real solutions as I build this system.

---

*Follow along as I develop an autonomous racing perception system!*